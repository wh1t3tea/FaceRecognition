{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 37705,
     "sourceType": "datasetVersion",
     "datasetId": 29561
    },
    {
     "sourceId": 7618879,
     "sourceType": "datasetVersion",
     "datasetId": 4437593
    }
   ],
   "dockerImageVersionId": 30648,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install facenet_pytorch"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-02-19T09:25:25.483965Z",
     "iopub.execute_input": "2024-02-19T09:25:25.484302Z",
     "iopub.status.idle": "2024-02-19T09:25:39.231596Z",
     "shell.execute_reply.started": "2024-02-19T09:25:25.484277Z",
     "shell.execute_reply": "2024-02-19T09:25:39.230136Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting facenet_pytorch\n  Downloading facenet_pytorch-2.5.3-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from facenet_pytorch) (1.24.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from facenet_pytorch) (2.31.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from facenet_pytorch) (0.16.2)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from facenet_pytorch) (9.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->facenet_pytorch) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->facenet_pytorch) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->facenet_pytorch) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->facenet_pytorch) (2023.11.17)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchvision->facenet_pytorch) (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchvision->facenet_pytorch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->torchvision->facenet_pytorch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchvision->facenet_pytorch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchvision->facenet_pytorch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision->facenet_pytorch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->torchvision->facenet_pytorch) (2023.12.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchvision->facenet_pytorch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchvision->facenet_pytorch) (1.3.0)\nDownloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.9/1.9 MB\u001B[0m \u001B[31m31.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n\u001B[?25hInstalling collected packages: facenet_pytorch\nSuccessfully installed facenet_pytorch-2.5.3\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from facenet_pytorch import MTCNN\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision import transforms as tfs\n",
    "import random"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-19T09:25:39.234014Z",
     "iopub.execute_input": "2024-02-19T09:25:39.234456Z",
     "iopub.status.idle": "2024-02-19T09:25:44.127214Z",
     "shell.execute_reply.started": "2024-02-19T09:25:39.234411Z",
     "shell.execute_reply": "2024-02-19T09:25:44.126250Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class MTCNN_Dataset(Dataset):\n",
    "    def __init__(self, imgs_path, labels_path, mode, subset=None, transform=None):\n",
    "        super().__init__()\n",
    "        self.imgs_folder = imgs_path\n",
    "        self.labels = pd.read_csv(labels_path, sep=\" \", header=None)\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        \n",
    "        if mode == 'rec':\n",
    "            if subset == 'train':\n",
    "                labels = self.labels[:162770]\n",
    "            elif subset == 'val':\n",
    "                labels = self.labels[162770:182637]\n",
    "            elif subset == 'test':\n",
    "                labels = self.labels[182637:]\n",
    "            elif subset == 'all':\n",
    "                labels = self.labels\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.mode == 'rec':\n",
    "            return len(labels)\n",
    "        else:\n",
    "            return len(self.labels)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "                idx = idx.tolist()\n",
    "        if self.mode == 'rec':\n",
    "            img_name, label = labels.iloc[idx]\n",
    "            img_path = os.path.join(imgs_path, img_name)\n",
    "            img = Image.open(img_path)\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, label\n",
    "        elif self.mode == 'detect':\n",
    "            img_name = self.labels.iloc[:, 0].iloc[idx]\n",
    "            img_path = os.path.join(imgs_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = torch.tensor(img)\n",
    "            return img, img_name"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-19T09:25:44.128326Z",
     "iopub.execute_input": "2024-02-19T09:25:44.128728Z",
     "iopub.status.idle": "2024-02-19T09:25:44.141122Z",
     "shell.execute_reply.started": "2024-02-19T09:25:44.128702Z",
     "shell.execute_reply": "2024-02-19T09:25:44.139674Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "imgs_path = '/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba'\n",
    "labels_path = '/kaggle/input/celeba-identity/identity_CelebA.txt'\n",
    "full_set = MTCNN_Dataset(imgs_path, labels_path, mode='detect')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-19T09:25:44.143300Z",
     "iopub.execute_input": "2024-02-19T09:25:44.143587Z",
     "iopub.status.idle": "2024-02-19T09:25:44.378295Z",
     "shell.execute_reply.started": "2024-02-19T09:25:44.143565Z",
     "shell.execute_reply": "2024-02-19T09:25:44.377490Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataloader = DataLoader(full_set, 128, shuffle=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-19T09:25:44.379411Z",
     "iopub.execute_input": "2024-02-19T09:25:44.379701Z",
     "iopub.status.idle": "2024-02-19T09:25:44.384539Z",
     "shell.execute_reply.started": "2024-02-19T09:25:44.379677Z",
     "shell.execute_reply": "2024-02-19T09:25:44.383584Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def show_imgs(dataloader, n_imgs):\n",
    "    batch, _ = next(iter(dataloader))\n",
    "    imgs = random.sample(batch.tolist(), n_imgs)\n",
    "    set_size = 0\n",
    "    if len(imgs) % 2 == 0:\n",
    "        set_size = 2\n",
    "    elif len(imgs) % 3 == 0:\n",
    "        set_size = 3\n",
    "    else:\n",
    "        set_size = 1\n",
    "    n_rows = len(imgs) // set_size\n",
    "    n_cols = len(imgs) // n_rows\n",
    "    for img_idx in range(len(imgs)):\n",
    "        plt.subplot(n_rows, n_cols, img_idx+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(imgs[img_idx])\n",
    "    plt.subplots_adjust(hspace=0.05, wspace = 0.05)\n",
    "    plt.show();"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-13T17:04:22.094043Z",
     "iopub.execute_input": "2024-02-13T17:04:22.094523Z",
     "iopub.status.idle": "2024-02-13T17:04:22.102069Z",
     "shell.execute_reply.started": "2024-02-13T17:04:22.094486Z",
     "shell.execute_reply": "2024-02-13T17:04:22.101184Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def align_face(image,\n",
    "               bbox: list | np.ndarray,\n",
    "               landmarks: list | np.ndarray,\n",
    "               image_size: tuple = (160, 160)) -> np.ndarray:\n",
    "    left_eye = landmarks[0]\n",
    "    right_eye = landmarks[1]\n",
    "\n",
    "    # Calculate angle between the eyes\n",
    "    dy = right_eye[1] - left_eye[1]\n",
    "    dx = right_eye[0] - left_eye[0]\n",
    "    angle = np.arctan2(dy, dx) * 180.0 / np.pi\n",
    "\n",
    "    # Calculate center of eyes\n",
    "    eyes_center = ((left_eye[0] + right_eye[0]) // 2, (left_eye[1] + right_eye[1]) // 2)\n",
    "\n",
    "    # Rotate image around the center of the eyes\n",
    "    rot_matrix = cv2.getRotationMatrix2D(eyes_center, angle, scale=1)\n",
    "    aligned_face = cv2.warpAffine(image, rot_matrix, (image.shape[1], image.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    if any(coord < 0 for coord in bbox):\n",
    "        return None\n",
    "    \n",
    "    x1, y1, x2, y2 = bbox\n",
    "    \n",
    "    cropped_aligned_face = aligned_face[y1:y2, x1:x2]\n",
    "\n",
    "    cropped_aligned_face = cv2.resize(cropped_aligned_face, dsize=image_size)\n",
    "\n",
    "    return torch.tensor(cropped_aligned_face)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-19T09:25:56.599535Z",
     "iopub.execute_input": "2024-02-19T09:25:56.599919Z",
     "iopub.status.idle": "2024-02-19T09:25:56.608897Z",
     "shell.execute_reply.started": "2024-02-19T09:25:56.599890Z",
     "shell.execute_reply": "2024-02-19T09:25:56.607935Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class FaceExtractor(nn.Module):\n",
    "    def __init__(self, detector, device='cpu', img_size=(160, 160)):\n",
    "        super(FaceExtractor, self).__init__()\n",
    "        self.model = detector\n",
    "        self.model.device = device\n",
    "        self.img_size = img_size\n",
    "    \n",
    "    def get_bbox_landmarks(self, img_batch):\n",
    "        bbox_batch, proba_batch, landmarks_batch = self.model.detect(img_batch, landmarks=True)\n",
    "        results = {'bbox': [],\n",
    "                   'landmarks': [],\n",
    "                   'proba': []}\n",
    "        for bbox, proba, landmarks in zip(bbox_batch, proba_batch, landmarks_batch):\n",
    "            if bbox is not None and proba is not None and landmarks is not None:\n",
    "                if proba is not None:\n",
    "                    proba = proba[0]\n",
    "                bbox = [int(coord) for coord in bbox[0]]\n",
    "                landmarks = landmarks[0]\n",
    "                results['bbox'].append(bbox)\n",
    "                results['landmarks'].append(landmarks)\n",
    "                results['proba'].append(proba)\n",
    "            else:\n",
    "                results['bbox'].append(None)\n",
    "                results['landmarks'].append(None)\n",
    "                results['proba'].append(None)\n",
    "        return results\n",
    "    \n",
    "    def npAngle(self, a, b, c):\n",
    "        ba = np.array(a) - np.array(b)\n",
    "        bc = np.array(c) - np.array(b) \n",
    "\n",
    "        cosine_angle = np.dot(ba, bc)/(np.linalg.norm(ba)*np.linalg.norm(bc))\n",
    "        angle = np.arccos(cosine_angle)\n",
    "\n",
    "        return np.degrees(angle)\n",
    "    \n",
    "    def predFacePose(self, bbox_, landmarks_, prob_):\n",
    "    \n",
    "        angle_R_List = []\n",
    "        angle_L_List = []\n",
    "        predLabelList = []\n",
    "\n",
    "        for bbox, landmarks, prob in zip(bbox_, landmarks_, prob_):\n",
    "            if bbox is not None: # To check if we detect a face in the image\n",
    "                if prob > 0.9: # To check if the detected face has probability more than 90%, to avoid \n",
    "                    angR = self.npAngle(landmarks[0], landmarks[1], landmarks[2]) # Calculate the right eye angle\n",
    "                    angL = self.npAngle(landmarks[1], landmarks[0], landmarks[2])# Calculate the left eye angle\n",
    "                    angle_R_List.append(angR)\n",
    "                    angle_L_List.append(angL)\n",
    "                    if ((int(angR) in range(30, 66)) and (int(angL) in range(30, 66))):\n",
    "                        predLabel='Frontal'\n",
    "                        predLabelList.append(predLabel)\n",
    "                    else:\n",
    "                        if angR < angL:\n",
    "                            predLabel='Left Profile'\n",
    "                        else:\n",
    "                            predLabel='Right Profile'\n",
    "                        predLabelList.append(predLabel)\n",
    "                else:\n",
    "                    predLabelList.append(None)\n",
    "                    angle_R_List.append(None)\n",
    "                    angle_L_List.append(None)\n",
    "            else:\n",
    "                predLabelList.append(None)\n",
    "                angle_R_List.append(None)\n",
    "                angle_L_List.append(None)\n",
    "                \n",
    "        face_d = {'angle_right': angle_R_List,\n",
    "                'angle_left': angle_L_List,\n",
    "                'label': predLabelList}\n",
    "                \n",
    "        return face_d\n",
    "\n",
    "    def forward(self, img_batch):\n",
    "        outps = self.get_bbox_landmarks(img_batch)\n",
    "        aligned_faces = []\n",
    "        bbox, landmarks, proba = outps['bbox'], outps['landmarks'], outps['proba']\n",
    "        face_d = zip(bbox, landmarks, proba)\n",
    "        angles = self.predFacePose(bbox, landmarks, proba)\n",
    "        angles = angles['label']\n",
    "        for idx, (face_data, angle) in enumerate(zip(face_d, angles)):\n",
    "            if face_data is not None:\n",
    "                if angle == 'Frontal':\n",
    "                    bbox, landmarks, proba = face_data\n",
    "                    aligned_faces.append(align_face(np.array(img_batch[idx]), bbox, landmarks, self.img_size))\n",
    "                else:\n",
    "                    aligned_faces.append(None)\n",
    "            else:\n",
    "                aligned_faces.append(None)\n",
    "        return np.array(aligned_faces, dtype='object')\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-19T10:24:22.618406Z",
     "iopub.execute_input": "2024-02-19T10:24:22.619110Z",
     "iopub.status.idle": "2024-02-19T10:24:22.639674Z",
     "shell.execute_reply.started": "2024-02-19T10:24:22.619082Z",
     "shell.execute_reply": "2024-02-19T10:24:22.638622Z"
    },
    "trusted": true
   },
   "execution_count": 163,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "mtcnn = MTCNN(device='cuda:0', keep_all=False, thresholds=[0.6, 0.8, 0.92], selection_method='probability')\n",
    "model = FaceExtractor(mtcnn, device='cuda:0')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-19T10:24:23.098027Z",
     "iopub.execute_input": "2024-02-19T10:24:23.098982Z",
     "iopub.status.idle": "2024-02-19T10:24:23.125285Z",
     "shell.execute_reply.started": "2024-02-19T10:24:23.098939Z",
     "shell.execute_reply": "2024-02-19T10:24:23.124490Z"
    },
    "trusted": true
   },
   "execution_count": 164,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def detect_and_save_batch(model, dir_name, dataloader, device='cuda:0'):\n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        bad_imgs = []\n",
    "        for batch, filenames in dataloader:\n",
    "            cropped_faces = model(batch)\n",
    "            for img, filename in zip(cropped_faces, filenames):\n",
    "                if isinstance(img, np.ndarray):\n",
    "                    img = torch.tensor(img.astype('uint8'))\n",
    "                if img is None:\n",
    "                    bad_imgs.append(filename)\n",
    "                    print(f\"Faces wasn't detected: {len(bad_imgs)}\")\n",
    "                    continue\n",
    "                img = img.permute(2, 0, 1) / 255\n",
    "                img_path = os.path.join(dir_name, filename)\n",
    "                os.makedirs(dir_name, exist_ok=True)\n",
    "                save_image(img, img_path)\n",
    "    print('All images were successfully uploaded!')\n",
    "    return bad_imgs\n",
    "            "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-19T10:24:23.534526Z",
     "iopub.execute_input": "2024-02-19T10:24:23.535247Z",
     "iopub.status.idle": "2024-02-19T10:24:23.544679Z",
     "shell.execute_reply.started": "2024-02-19T10:24:23.535216Z",
     "shell.execute_reply": "2024-02-19T10:24:23.543575Z"
    },
    "trusted": true
   },
   "execution_count": 165,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "root = '/kaggle/working/celeba_cropped_'\n",
    "device = 'cuda:0'"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-19T10:24:24.046827Z",
     "iopub.execute_input": "2024-02-19T10:24:24.047636Z",
     "iopub.status.idle": "2024-02-19T10:24:24.051391Z",
     "shell.execute_reply.started": "2024-02-19T10:24:24.047604Z",
     "shell.execute_reply": "2024-02-19T10:24:24.050456Z"
    },
    "trusted": true
   },
   "execution_count": 166,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "to_drop = detect_and_save_batch(model, root, dataloader, device)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "annot = pd.read_csv('/kaggle/input/celeba-identity/identity_CelebA.txt', sep=' ', names=['Image_name', 'Label'])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-19T11:23:23.837283Z",
     "iopub.execute_input": "2024-02-19T11:23:23.837644Z",
     "iopub.status.idle": "2024-02-19T11:23:23.983001Z",
     "shell.execute_reply.started": "2024-02-19T11:23:23.837616Z",
     "shell.execute_reply": "2024-02-19T11:23:23.982144Z"
    },
    "trusted": true
   },
   "execution_count": 168,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(to_drop))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-19T11:35:37.345009Z",
     "iopub.execute_input": "2024-02-19T11:35:37.345521Z",
     "iopub.status.idle": "2024-02-19T11:35:37.350910Z",
     "shell.execute_reply.started": "2024-02-19T11:35:37.345483Z",
     "shell.execute_reply": "2024-02-19T11:35:37.349857Z"
    },
    "trusted": true
   },
   "execution_count": 178,
   "outputs": [
    {
     "name": "stdout",
     "text": "41100\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "idx = annot[(annot['Image_name'].isin(to_drop))].index"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-19T11:24:22.970469Z",
     "iopub.execute_input": "2024-02-19T11:24:22.970838Z",
     "iopub.status.idle": "2024-02-19T11:24:23.035215Z",
     "shell.execute_reply.started": "2024-02-19T11:24:22.970808Z",
     "shell.execute_reply": "2024-02-19T11:24:23.034257Z"
    },
    "trusted": true
   },
   "execution_count": 171,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "annot.drop(index=idx, axis=0, inplace=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-19T11:24:24.119319Z",
     "iopub.execute_input": "2024-02-19T11:24:24.120009Z",
     "iopub.status.idle": "2024-02-19T11:24:24.138854Z",
     "shell.execute_reply.started": "2024-02-19T11:24:24.119980Z",
     "shell.execute_reply": "2024-02-19T11:24:24.138087Z"
    },
    "trusted": true
   },
   "execution_count": 172,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "annot"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-19T11:25:33.066122Z",
     "iopub.execute_input": "2024-02-19T11:25:33.066796Z",
     "iopub.status.idle": "2024-02-19T11:25:33.081416Z",
     "shell.execute_reply.started": "2024-02-19T11:25:33.066766Z",
     "shell.execute_reply": "2024-02-19T11:25:33.080417Z"
    },
    "trusted": true
   },
   "execution_count": 173,
   "outputs": [
    {
     "execution_count": 173,
     "output_type": "execute_result",
     "data": {
      "text/plain": "        Image_name  Label\n1       000002.jpg   2937\n5       000006.jpg   4153\n6       000007.jpg   9040\n7       000008.jpg   6369\n8       000009.jpg   3332\n...            ...    ...\n202594  202595.jpg   9761\n202595  202596.jpg   7192\n202596  202597.jpg   9852\n202597  202598.jpg   5570\n202598  202599.jpg  10101\n\n[161499 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_name</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>000002.jpg</td>\n      <td>2937</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>000006.jpg</td>\n      <td>4153</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>000007.jpg</td>\n      <td>9040</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>000008.jpg</td>\n      <td>6369</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>000009.jpg</td>\n      <td>3332</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>202594</th>\n      <td>202595.jpg</td>\n      <td>9761</td>\n    </tr>\n    <tr>\n      <th>202595</th>\n      <td>202596.jpg</td>\n      <td>7192</td>\n    </tr>\n    <tr>\n      <th>202596</th>\n      <td>202597.jpg</td>\n      <td>9852</td>\n    </tr>\n    <tr>\n      <th>202597</th>\n      <td>202598.jpg</td>\n      <td>5570</td>\n    </tr>\n    <tr>\n      <th>202598</th>\n      <td>202599.jpg</td>\n      <td>10101</td>\n    </tr>\n  </tbody>\n</table>\n<p>161499 rows × 2 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "annot.to_csv('Identity_CelebA.txt', sep=' ')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-19T11:26:35.303573Z",
     "iopub.execute_input": "2024-02-19T11:26:35.303943Z",
     "iopub.status.idle": "2024-02-19T11:26:35.618660Z",
     "shell.execute_reply.started": "2024-02-19T11:26:35.303913Z",
     "shell.execute_reply": "2024-02-19T11:26:35.617884Z"
    },
    "trusted": true
   },
   "execution_count": 174,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "shutil.make_archive('celeba_aligned', 'zip', '/kaggle/working/celeba_cropped_')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-19T11:27:37.576537Z",
     "iopub.execute_input": "2024-02-19T11:27:37.576897Z",
     "iopub.status.idle": "2024-02-19T11:28:21.559016Z",
     "shell.execute_reply.started": "2024-02-19T11:27:37.576869Z",
     "shell.execute_reply": "2024-02-19T11:28:21.558033Z"
    },
    "trusted": true
   },
   "execution_count": 177,
   "outputs": [
    {
     "execution_count": 177,
     "output_type": "execute_result",
     "data": {
      "text/plain": "'/kaggle/working/celeba_aligned.zip'"
     },
     "metadata": {}
    }
   ]
  }
 ]
}
